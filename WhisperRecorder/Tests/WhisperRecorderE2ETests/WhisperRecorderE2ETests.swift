import XCTest
import SwiftUI
import AVFoundation
@testable import WhisperRecorder

// Import TestAudioGenerator from unit tests
@testable import WhisperRecorderTests

/// E2E tests for WhisperRecorder - test the entire system completely
class WhisperRecorderE2ETests: XCTestCase {
    
    var audioRecorder: AudioRecorder!
    var originalLastTranscription: String?
    var originalLastProcessedText: String?
    
    override func setUp() {
        super.setUp()
        
        print("üß™ Setting up E2E test environment...")
        
        // Store original values
        originalLastTranscription = audioRecorder?.lastTranscription
        originalLastProcessedText = AppDelegate.lastProcessedText
        
        // Initialize AudioRecorder
        audioRecorder = AudioRecorder.shared
        
        // Wait for system to be ready
        let readyExpectation = expectation(description: "AudioRecorder ready")
        
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
            readyExpectation.fulfill()
        }
        
        wait(for: [readyExpectation], timeout: 5.0)
        print("‚úÖ E2E test environment ready")
    }
    
    override func tearDown() {
        // Restore original values
        if let originalTranscription = originalLastTranscription {
            audioRecorder.setLastTranscriptionForTesting(originalTranscription)
        }
        if let originalProcessedText = originalLastProcessedText {
            AppDelegate.lastProcessedText = originalProcessedText
        }
        
        super.tearDown()
    }
    
    // MARK: - Basic E2E Flow Tests
    
    func testCompleteTranscriptionFlow() async throws {
        print("üéØ Testing complete transcription flow...")
        
        // Given: Synthetic audio buffer
        let audioBuffer = TestAudioGenerator.createSpeechLikeAudioBuffer(duration: 3.0)
        XCTAssertFalse(audioBuffer.isEmpty, "Audio buffer should not be empty")
        XCTAssertGreaterThan(audioBuffer.count, 16000, "Audio buffer should have reasonable size")
        
        // Check that system is ready
        XCTAssertNotNil(audioRecorder, "AudioRecorder should be initialized")
        
        // When: Process audio through complete pipeline
        let transcriptionExpectation = expectation(description: "Transcription completed")
        var finalTranscription: String?
        var processingTime: TimeInterval = 0
        
        let startTime = Date()
        
        // Simulate audio buffer processing
        await MainActor.run {
            // Set up callback to receive result
            let originalCallback = audioRecorder.onStatusUpdate
            audioRecorder.onStatusUpdate = { [weak self] in
                originalCallback?()
                
                if let transcription = self?.audioRecorder.lastTranscription,
                   !transcription.isEmpty,
                                       !(self?.audioRecorder.isTranscribing ?? true) {
                    finalTranscription = transcription
                    processingTime = Date().timeIntervalSince(startTime)
                    transcriptionExpectation.fulfill()
                }
            }
        }
        
        // Start transcription through private method (reflection)
        try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<Void, Error>) in
            DispatchQueue.global(qos: .userInitiated).async {
                // Use reflection to access private method
                let mirror = Mirror(reflecting: self.audioRecorder!)
                
                // Alternatively - simulate through AudioEngineManager
                DispatchQueue.main.async {
                    // Set "transcribing" state
                    self.audioRecorder.setIsTranscribingForTesting(true)
                    self.audioRecorder.statusDescription = "Transcribing..."
                    
                    // Simulate transcribeAudioBuffer call
                    self.simulateTranscription(audioBuffer: audioBuffer)
                    
                    continuation.resume()
                }
            }
        }
        
        // Then: Wait for transcription completion
        await fulfillment(of: [transcriptionExpectation], timeout: 30.0)
        
        // Check results
        XCTAssertNotNil(finalTranscription, "Should receive transcription result")
        XCTAssertFalse(finalTranscription!.isEmpty, "Transcription should not be empty")
        XCTAssertLessThan(processingTime, 15.0, "Processing should complete within reasonable time")
        XCTAssertFalse(audioRecorder.isTranscribing, "Should not be transcribing after completion")
        XCTAssertEqual(audioRecorder.statusDescription, "Ready", "Should return to ready state")
        
        print("‚úÖ Complete transcription flow test passed")
        print("üìä Processing time: \(String(format: "%.2f", processingTime))s")
        print("üìù Transcription result: \(finalTranscription?.prefix(50) ?? "nil")...")
    }
    
    func testTranscriptionWithDifferentAudioTypes() async throws {
        print("üéØ Testing transcription with different audio types...")
        
        // Test only safe generators for now
        let testCases: [(name: String, generator: () -> [Float])] = [
            ("Short speech", { TestAudioGenerator.createSpeechLikeAudioBuffer(duration: 2.0) }),
            ("Quick test", { TestAudioGenerator.createQuickTestBuffer() })
        ]
        
        for (testName, generator) in testCases {
            print("  üîç Testing: \(testName)")
            
            let audioBuffer = generator()
            print("    üìä Generated buffer size: \(audioBuffer.count)")
            XCTAssertFalse(audioBuffer.isEmpty, "\(testName): Audio buffer should not be empty")
            
            // Simulate transcription
            let result = await simulateTranscriptionAsync(audioBuffer: audioBuffer)
            
            XCTAssertNotNil(result, "\(testName): Should return transcription result")
            print("    ‚úÖ \(testName): Success")
        }
        
        print("‚úÖ Different audio types test completed")
    }
    
    // MARK: - Performance E2E Tests
    
    func testTranscriptionPerformance() async throws {
        print("üéØ Testing transcription performance...")
        
        let audioBuffer = TestAudioGenerator.createSpeechLikeAudioBuffer(duration: 10.0)
        
        measure(metrics: [XCTClockMetric(), XCTMemoryMetric()]) {
            let expectation = self.expectation(description: "Performance test completion")
            
            Task {
                let startTime = Date()
                let result = await self.simulateTranscriptionAsync(audioBuffer: audioBuffer)
                let processingTime = Date().timeIntervalSince(startTime)
                
                XCTAssertNotNil(result)
                XCTAssertLessThan(processingTime, 20.0, "Processing should be reasonably fast")
                
                expectation.fulfill()
            }
            
            wait(for: [expectation], timeout: 30.0)
        }
        
        print("‚úÖ Performance test completed")
    }
    
    func testLargeAudioFileHandling() async throws {
        print("üéØ Testing large audio file handling...")
        
        // Create "large" audio file (1 minute)
        let largeAudioBuffer = TestAudioGenerator.createLongTestBuffer()
        XCTAssertGreaterThan(largeAudioBuffer.count, 16000 * 50, "Should be a substantial audio buffer")
        
        let startTime = Date()
        let result = await simulateTranscriptionAsync(audioBuffer: largeAudioBuffer)
        let processingTime = Date().timeIntervalSince(startTime)
        
        XCTAssertNotNil(result, "Should handle large audio files")
        XCTAssertLessThan(processingTime, 60.0, "Should process large files within reasonable time")
        
        print("‚úÖ Large audio file test completed")
        print("üìä Large file processing time: \(String(format: "%.2f", processingTime))s")
    }
    
    // MARK: - Error Handling E2E Tests
    
    func testErrorRecovery() async throws {
        print("üéØ Testing error recovery...")
        
        // Test 1: Empty audio buffer
        let emptyBuffer: [Float] = []
        let _ = await simulateTranscriptionAsync(audioBuffer: emptyBuffer)
        // System should gracefully handle empty buffer
        
        // Test 2: Very short buffer
        let tinyBuffer = Array<Float>(repeating: 0.1, count: 100) // Very short
        let _ = await simulateTranscriptionAsync(audioBuffer: tinyBuffer)
        
        // Test 3: Very large buffer
        let hugeBuffer = Array<Float>(repeating: 0.1, count: 16000 * 600) // 10 minutes
        let _ = await simulateTranscriptionAsync(audioBuffer: hugeBuffer)
        
        print("‚úÖ Error recovery tests completed")
    }
    
    // MARK: - State Management E2E Tests
    
    func testConcurrentOperations() async throws {
        print("üéØ Testing concurrent operations...")
        
        let audioBuffer1 = TestAudioGenerator.createSpeechLikeAudioBuffer(duration: 2.0)
        let audioBuffer2 = TestAudioGenerator.createSpeechLikeAudioBuffer(duration: 3.0)
        
        // Start two operations simultaneously
        async let result1 = simulateTranscriptionAsync(audioBuffer: audioBuffer1)
        async let result2 = simulateTranscriptionAsync(audioBuffer: audioBuffer2)
        
        let (_, _) = await (result1, result2)
        
        // Both operations should complete successfully
        // (or second should wait for first, depending on implementation)
        
        print("‚úÖ Concurrent operations test completed")
    }
    
    func testStateTransitions() async throws {
        print("üéØ Testing state transitions...")
        
        // Check initial state
        XCTAssertFalse(audioRecorder.isTranscribing, "Should start in non-transcribing state")
        XCTAssertEqual(audioRecorder.statusDescription, "Ready", "Should start in ready state")
        
        let audioBuffer = TestAudioGenerator.createQuickTestBuffer()
        
        // Manually test state changes
        await MainActor.run {
            // Simulate transcription start
            audioRecorder.setIsTranscribingForTesting(true)
            audioRecorder.statusDescription = "Transcribing..."
        }
        
        XCTAssertTrue(audioRecorder.isTranscribing, "Should be transcribing")
        XCTAssertEqual(audioRecorder.statusDescription, "Transcribing...", "Should show transcribing status")
        
        // Simulate transcription completion
        await MainActor.run {
            audioRecorder.setLastTranscriptionForTesting("Test transcription result")
            audioRecorder.setIsTranscribingForTesting(false)
            audioRecorder.statusDescription = "Ready"
        }
        
        XCTAssertFalse(audioRecorder.isTranscribing, "Should finish transcribing")
        XCTAssertEqual(audioRecorder.statusDescription, "Ready", "Should return to ready state")
        XCTAssertNotNil(audioRecorder.lastTranscription, "Should have transcription result")
        
        print("‚úÖ State transitions test completed")
    }
    
    // MARK: - Helper Methods
    
    /// Simulates audio buffer transcription
    private func simulateTranscription(audioBuffer: [Float]) {
        // Simulate real transcription process
        DispatchQueue.global(qos: .userInitiated).async {
            // Simulate processing
            Thread.sleep(forTimeInterval: 0.5) // Minimal delay
            
            DispatchQueue.main.async {
                // Simulate transcription result
                let simulatedResult = "This is a simulated transcription result for testing purposes."
                
                // Update state
                self.audioRecorder.setLastTranscriptionForTesting(simulatedResult)
                self.audioRecorder.setIsTranscribingForTesting(false)
                self.audioRecorder.statusDescription = "Ready"
                
                // Call callback
                self.audioRecorder.onStatusUpdate?()
            }
        }
    }
    
    /// Async version of transcription simulation
    private func simulateTranscriptionAsync(audioBuffer: [Float]) async -> String? {
        return await withCheckedContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                // Simulate processing time proportional to buffer size
                let processingTime = min(0.1 + Double(audioBuffer.count) / 320000.0, 5.0)
                Thread.sleep(forTimeInterval: processingTime)
                
                let result = audioBuffer.isEmpty ? nil : "Simulated transcription for \(audioBuffer.count) samples"
                continuation.resume(returning: result)
            }
        }
    }
}

// MARK: - Extensions for Testing

extension AudioRecorder {
    /// Test helper to access lastTranscription for verification
    var testLastTranscription: String? {
        return lastTranscription
    }
    
    /// Test helper to check if system is ready
    var isSystemReady: Bool {
        return !isTranscribing && statusDescription == "Ready"
    }
} 